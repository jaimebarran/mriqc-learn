{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b7563a",
   "metadata": {},
   "source": [
    "Loading my dataset their way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e28d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score as auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mriqc_learn.datasets import load_dataset\n",
    "from mriqc_learn.models import preprocess as pp\n",
    "from mriqc_learn.models.production import init_pipeline\n",
    "from mriqc_learn.model_selection import split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c51b72",
   "metadata": {},
   "source": [
    "## Load some data\n",
    "We first load the ABIDE dataset, one of the default datasets distributed with MRIQC-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973dc0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (_, _) = load_dataset(dataset=\"SHIP183\", split_strategy=\"none\")\n",
    "train_x[\"site\"] = train_y.site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f8885",
   "metadata": {},
   "source": [
    "Let's pick the ratings from \"rater_3\" and binarize the three categories into only two.\n",
    "We can also see that the dataset is unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y[[\"rating\"]].values.squeeze().astype(int)\n",
    "print(f'Excluded={100 * (train_y == 1).sum() / len(train_y) :.2f}%')\n",
    "print(f'Accept={100 * (train_y == 0).sum() / len(train_y) :.2f}%')\n",
    "train_y[train_y >= 1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4ec3e",
   "metadata": {},
   "source": [
    "Let's print out a pretty view of the data table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c76905",
   "metadata": {},
   "source": [
    "## Cross-validation of the default classifier\n",
    "Let's cross-validate the performance of our classifier using a Leave-one-site-out strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a splitting strategy\n",
    "outer_cv = split.LeavePSitesOut(1, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992f5cc",
   "metadata": {},
   "source": [
    "We can now feed the model into the cross-validation loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(\n",
    "    init_pipeline(),\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc225b6",
   "metadata": {},
   "source": [
    "After one or two minutes, the scores have been caculated for each of the 14 folds our splitter created.\n",
    "The average performance is AUC=0.885."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_score)\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cv_score = {}\n",
    "for train_index, (site, test_index) in outer_cv.split(train_x, y=train_y, return_key=True):\n",
    "    # Validate on test fold\n",
    "    print(f\"Validating on left-out site ({site})...\")\n",
    "    model_split = init_pipeline()\n",
    "    model_split = model_split.fit(train_x.iloc[train_index], train_y[train_index])\n",
    "    custom_cv_score[site] = auc(train_y[test_index], model_split.predict(train_x.iloc[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_cv_score)\n",
    "np.mean(list(custom_cv_score.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622dc24",
   "metadata": {},
   "source": [
    "We now train the model on all available training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_pipeline().fit(\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(model, \"/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/mriqc_learn/data/classifier_N183_NoBrainIQMs.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ac340",
   "metadata": {},
   "source": [
    "We can easily see the effects of overfitting by evaluating the classifier on the same folds we used for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_cv_score = {}\n",
    "for train_index, (site, test_index) in outer_cv.split(train_x, y=train_y, return_key=True):\n",
    "    print(f\"Validating on left-out site ({site})...\")\n",
    "    overfit_cv_score[site] = auc(train_y[test_index], model.predict(train_x.iloc[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([overfit_cv_score[s] - custom_cv_score[s] for s in overfit_cv_score.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(train_y, model.predict(train_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4292f",
   "metadata": {},
   "source": [
    "## Evaluating on held-out dataset\n",
    "We first load the held-out dataset in, and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_x, test_y), (_, _) = load_dataset(\"ds030\", split_strategy=\"none\")\n",
    "test_x[\"site\"] = test_y.site\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_ghost = test_y.has_ghost.values.astype(bool)\n",
    "test_y = test_y[[\"rater_1\"]].values.squeeze().astype(int)\n",
    "print(f\"Discard={100 * (test_y == -1).sum() / len(test_y)}\")\n",
    "print(f\"Doubtful={100 * (test_y == 0).sum() / len(test_y)}\")\n",
    "print(f\"Accept={100 * (test_y == 1).sum() / len(test_y)}\")\n",
    "test_y[test_y < 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(test_y, model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33792116",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(test_y[~has_ghost], model.predict(test_x[~has_ghost]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, model.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y[~has_ghost], model.predict(test_x[~has_ghost])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cded3e3",
   "metadata": {},
   "source": [
    "## Nested cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e57e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = [{\n",
    "    \"scale__unit_variance\": [True, False],\n",
    "    \"scale__with_centering\": [True, False],\n",
    "    \"site_pred__disable\": [False, True],\n",
    "    \"winnow__disable\": [False, True],\n",
    "    \"svc__kernel\": [\"rbf\"],\n",
    "    \"svc__C\": [10],\n",
    "    \"svc__gamma\": [0.1],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV with parameter optimization\n",
    "inner_cv = split.LeavePSitesOut(1, robust=True)\n",
    "inner_cv.get_n_splits(X=train_x, y=train_y)\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=p_grid,\n",
    "    cv=inner_cv,\n",
    "    n_jobs=30,\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "# clf.fit(train_x, y=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d007f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_score = cross_val_score(\n",
    "    clf,\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    "    cv=outer_cv,\n",
    "    scoring=\"roc_auc\",\n",
    "    verbose=10,\n",
    "    n_jobs=16,\n",
    ")\n",
    "nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

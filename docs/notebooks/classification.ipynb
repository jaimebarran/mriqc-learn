{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mriqc_learn.datasets import load_dataset\n",
    "\n",
    "(train_x, train_y), (_, _) = load_dataset(dataset=\"SHIP183\", split_strategy=\"none\")\n",
    "train_x[\"site\"] = train_y.site\n",
    "\n",
    "train_y = train_y[[\"rating\"]].values.squeeze().astype(int)\n",
    "print(f'Excluded={100 * (train_y < 1).sum() / len(train_y)}')\n",
    "print(f'Accept={100 * (train_y >= 1).sum() / len(train_y)}')\n",
    "train_y[train_y >= 1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaimebarranco/miniconda3/envs/a-eye/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RobustScaler from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/jaimebarranco/miniconda3/envs/a-eye/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/jaimebarranco/miniconda3/envs/a-eye/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/jaimebarranco/miniconda3/envs/a-eye/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the trained model\n",
    "model = load(\"/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/mriqc_learn/data/classifier.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the new dataset\n",
    "ds_aux = pd.read_csv(\"/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/mriqc_learn/datasets/SHIP1210.tsv\", sep=\"\\t\")\n",
    "# ds from the 3rd column\n",
    "ds = ds_aux.iloc[:, 1:] # 2 if dataset contains ratings, 1 if not\n",
    "# move first column to the last\n",
    "ds = ds[[c for c in ds if c not in [\"site\"]] + [\"site\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from mriqc_learn.models import preprocess as pp\n",
    "\n",
    "# Preprocess the new dataset\n",
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        # (\n",
    "        #     \"drop_ft\",\n",
    "        #     pp.DropColumns(\n",
    "        #         drop=[f\"size_{ax}\" for ax in \"xyz\"] + [f\"spacing_{ax}\" for ax in \"xyz\"]\n",
    "        #     ),\n",
    "        # ),\n",
    "        (\n",
    "            \"scale\",\n",
    "            pp.SiteRobustScaler(\n",
    "                with_centering=True,\n",
    "                with_scaling=True,\n",
    "            ),\n",
    "        ),\n",
    "        (\"site_pred\", pp.SiteCorrelationSelector()),\n",
    "        # (\"winnow\", pp.NoiseWinnowFeatSelect(use_classifier=True)),\n",
    "        # (\"drop_site\", pp.DropColumns(drop=[\"site\"])),\n",
    "        # (\n",
    "        #     \"rfc\",\n",
    "        #     RFC(\n",
    "        #         bootstrap=True,\n",
    "        #         class_weight=None,\n",
    "        #         criterion=\"gini\",\n",
    "        #         max_depth=10,\n",
    "        #         max_features=\"sqrt\",\n",
    "        #         max_leaf_nodes=None,\n",
    "        #         min_impurity_decrease=0.0,\n",
    "        #         min_samples_leaf=10,\n",
    "        #         min_samples_split=10,\n",
    "        #         min_weight_fraction_leaf=0.0,\n",
    "        #         n_estimators=400,\n",
    "        #         oob_score=True,\n",
    "        #     ),\n",
    "        # ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds_processed = preprocessor.fit_transform(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes of the new dataset\n",
    "y_pred = model.predict(ds_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the index of the excluded ones to a list\n",
    "excluded = []\n",
    "for i, x in enumerate(y_pred):\n",
    "    if x == 0:\n",
    "        excluded.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"bids_name\" of the indeces in \"excluded\" in \"df_aux\"\n",
    "excluded_bids = [] # bids names\n",
    "for i in excluded:\n",
    "    excluded_bids.append(ds_aux.iloc[i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reports names of the excluded subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97301/3310871597.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_3['bids_name'] = bids_names # add bids names\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset into a pandas DataFrame \n",
    "df = pd.read_csv('/home/jaimebarranco/Desktop/MRI-QC/mriqc/mriqc_non-labeled-dataset/group_T1w.tsv', sep='\\t')\n",
    "df = df.sort_values(by='bids_name') # order by df['bids_name']\n",
    "df_names = pd.read_csv('/home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset/bids_csv.csv', sep=',')\n",
    "df_names['bids_name'] = df_names['im'].str.split('/').str[-1].str.split('.').str[0]\n",
    "df_names = df_names.sort_values(by='bids_name') # order by df_names['sub']\n",
    "df['name'] = df_names['name']\n",
    "# move last column to second position\n",
    "cols = list(df)\n",
    "cols.insert(1, cols.pop(cols.index('name')))\n",
    "df = df.loc[:, cols]\n",
    "\n",
    "subs_ls = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/non_labeled_dataset'\n",
    "files_1 = [(os.path.basename(f)).split('.')[0] for f in sorted(os.listdir(subs_ls)) if not f.startswith('.')]\n",
    "files_1 = [int(f) for f in files_1] # files from string to int\n",
    "numbers_1 = [f for f in range(1, len(files_1)+1)]\n",
    "df_1 = pd.DataFrame({'Subject': files_1, 'Number': numbers_1})\n",
    "\n",
    "subs = '/home/jaimebarranco/Downloads/samples_v3'\n",
    "files_2 = [(os.path.basename(f)).split('.')[0] for f in sorted(os.listdir(subs)) if not f.startswith('.')]\n",
    "files_2 = [int(f) for f in files_2] # files from string to int\n",
    "numbers_2 = [f for f in range(1, len(files_2)+1)]\n",
    "df_2 = pd.DataFrame({'Subject': files_2, 'Number': numbers_2})\n",
    "\n",
    "# df_1 only with df_2 subjects\n",
    "df_3 = df_1[df_1['Subject'].isin(df_2['Subject'])]\n",
    "numbers_3 = df_3['Number']\n",
    "bids_names = [f'sub-{n:03}_T1w' for n in numbers_3]\n",
    "df_3['bids_name'] = bids_names # add bids names\n",
    "\n",
    "df_aux = pd.read_excel('/home/jaimebarranco/Desktop/MRI-QC/scores.xlsx', sheet_name='brainmask_avg_data')\n",
    "df_aux['bids_name'] = bids_names\n",
    "# move last column to second position\n",
    "cols = list(df_aux)\n",
    "cols.insert(1, cols.pop(cols.index('bids_name')))\n",
    "df_aux = df_aux.loc[:, cols]\n",
    "\n",
    "# subdataframe of df without the bids_names in df_aux\n",
    "df = df[~df['bids_name'].isin(df_aux['bids_name'])] # pure testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('/home/jaimebarranco/Desktop/MRI-QC/scores.xlsx', sheet_name='brainmask_avg_data') # old ones\n",
    "dfaux = pd.read_csv('/home/jaimebarranco/Desktop/MRI-QC/mriqc/mriqc_non-labeled-dataset/group_T1w.tsv', sep='\\t') # IQMs\n",
    "df2 = pd.read_excel('/home/jaimebarranco/Desktop/MRI-QC/excluded_edited.xlsx', sheet_name='excluded') # excluded (new ones)\n",
    "# remove subjects without 'my_rate'\n",
    "df2_filtered = df2[(~df2['my_rate'].isna()) & (df2['my_rate'] != '')]\n",
    "# dfaux only with the subjects in df2 in column 'bids_name'\n",
    "dfaux_filtered = dfaux[dfaux['bids_name'].isin(df2_filtered['bids_name'])]\n",
    "# reset 'index' column of dfaux_filtered to add ratings\n",
    "dfaux_filtered = dfaux_filtered.reset_index(drop=True)\n",
    "# insert 'my_rate' column from df2_filtered to dfaux_filtered\n",
    "dfaux_filtered['rating'] = df2_filtered['my_rate']\n",
    "cols = list(dfaux_filtered)\n",
    "cols.insert(1, cols.pop(cols.index('rating')))\n",
    "dfaux_filtered = dfaux_filtered.loc[:, cols]\n",
    "\n",
    "df1_aux = df1.drop(columns=['name','sub','subject','rating','rating_text','blur','blur_text','noise','noise_text','motion','motion_text','bgair','bgair_text'])\n",
    "df_3 = df_3.reset_index(drop=True)\n",
    "bids_names = df_3['bids_name']\n",
    "ratings = df1_aux['exclusion']\n",
    "df1_filtered = pd.DataFrame({'bids_name': bids_names, 'rating': ratings})\n",
    "# insert df1_aux into df1_filtered\n",
    "df1_aux = df1_aux.drop(columns=['exclusion'])\n",
    "df1_filtered = pd.concat([df1_filtered, df1_aux], axis=1)\n",
    "\n",
    "# join df1_filtered and dfaux_filtered\n",
    "df_merged = pd.concat([df1_filtered, dfaux_filtered], ignore_index=True)\n",
    "\n",
    "# large scale dataset = dfaux - df_merged\n",
    "df_ls_aux = dfaux.copy()\n",
    "df_ls_aux['name'] = df_names['name']\n",
    "df_ls = df_ls_aux[~df_ls_aux['bids_name'].isin(df_merged['bids_name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reports name of the indeces in \"excluded\" in \"df_ls\"\n",
    "excluded_names = [] # reports names\n",
    "for i in excluded:\n",
    "    excluded_names.append(df_ls_aux.iloc[i, list(df_ls_aux.columns).index('name')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded subjects: 21/1210\n",
      "       bids_name       name\n",
      "0    sub-072_T1w  sub-USOLR\n",
      "1   sub-1063_T1w  sub-IHOSM\n",
      "2   sub-1085_T1w  sub-THNQV\n",
      "3    sub-174_T1w  sub-FYOFI\n",
      "4    sub-178_T1w  sub-HDMRF\n",
      "5    sub-237_T1w  sub-KIPSN\n",
      "6    sub-245_T1w  sub-DPCYK\n",
      "7    sub-253_T1w  sub-LNDGX\n",
      "8    sub-274_T1w  sub-DCIUE\n",
      "9    sub-282_T1w  sub-RUBRL\n",
      "10   sub-566_T1w  sub-PHYIT\n",
      "11   sub-626_T1w  sub-IZDXI\n",
      "12   sub-666_T1w  sub-LQDAH\n",
      "13   sub-697_T1w  sub-HQITR\n",
      "14   sub-772_T1w  sub-OJULJ\n",
      "15   sub-831_T1w  sub-LVKSF\n",
      "16   sub-881_T1w  sub-UDSIN\n",
      "17   sub-926_T1w  sub-SIRXJ\n",
      "18   sub-938_T1w  sub-MIFZE\n",
      "19   sub-950_T1w  sub-OFJWM\n",
      "20   sub-952_T1w  sub-VKIMP\n"
     ]
    }
   ],
   "source": [
    "df_excluded = pd.DataFrame({'bids_name': excluded_bids, 'name': excluded_names})\n",
    "print(f\"Excluded subjects: {len(df_excluded)}/{len(y_pred)}\")\n",
    "print(df_excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy subjects' reports to a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "reports_folder = '/home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset'\n",
    "output_folder = '/home/jaimebarranco/Downloads/excluded_mriqclearn'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# copy html reports from reports_folder that match the subjects in excluded dataframe to output_folder\n",
    "for i in range(len(excluded)):\n",
    "    subject = df_excluded['name'].values[i]\n",
    "    for filename in os.listdir(reports_folder):\n",
    "        if filename.startswith(f'{subject}_report'):\n",
    "            shutil.copy(f'{reports_folder}/{filename}', f'{output_folder}/{filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-eye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

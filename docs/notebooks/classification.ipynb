{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the trained model\n",
    "model = load(\"/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/mriqc_learn/data/classifier2.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the new dataset\n",
    "ds_aux = pd.read_csv(\"/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/mriqc_learn/datasets/SHIP1210.tsv\", sep=\"\\t\")\n",
    "# ds from the 3rd column\n",
    "ds = ds_aux.iloc[:, 1:] # 1 if dataset contains ratings, 1 if not\n",
    "# move first column to the last\n",
    "ds = ds[[c for c in ds if c not in [\"site\"]] + [\"site\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluded subjects from ds_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add subjects whose 'rating' are 1 from 'ds_aux' to a list\n",
    "# excluded_dsaux = ds_aux.loc[ds_aux['rating'] == 1, 'bids_name'].tolist()\n",
    "# print(\"Excluded subjects: \", len(excluded_dsaux))\n",
    "# print(excluded_dsaux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from mriqc_learn.models import preprocess as pp\n",
    "\n",
    "# Preprocess the new dataset\n",
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"drop_ft\",\n",
    "            pp.DropColumns(\n",
    "                drop=[f\"size_{ax}\" for ax in \"xyz\"] + [f\"spacing_{ax}\" for ax in \"xyz\"]\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"scale\",\n",
    "            pp.SiteRobustScaler(\n",
    "                with_centering=True,\n",
    "                with_scaling=True,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"drop_brainIQMs\",\n",
    "            pp.DropColumns(\n",
    "                drop=[\n",
    "                    \"cjv\",\n",
    "                    \"cnr\",\n",
    "                    # \"efc\",\n",
    "                    # \"fber\",\n",
    "                    # \"fwhm_avg\",\n",
    "                    # \"fwhm_x\",\n",
    "                    # \"fwhm_y\",\n",
    "                    # \"fwhm_z\",\n",
    "                    \"icvs_csf\",\n",
    "                    \"icvs_gm\",\n",
    "                    \"icvs_wm\",\n",
    "                    # \"inu_med\",\n",
    "                    # \"inu_range\",\n",
    "                    \"qi_1\",\n",
    "                    # \"qi_2\",\n",
    "                    \"rpve_csf\",\n",
    "                    \"rpve_gm\",\n",
    "                    \"rpve_wm\",\n",
    "                    \"snr_csf\",\n",
    "                    \"snr_gm\",\n",
    "                    \"snr_total\",\n",
    "                    \"snr_wm\",\n",
    "                    \"snrd_csf\",\n",
    "                    \"snrd_gm\",\n",
    "                    # \"snrd_total\",\n",
    "                    \"snrd_wm\",\n",
    "                    \"summary_bg_k\",\n",
    "                    \"summary_bg_mad\",\n",
    "                    \"summary_bg_mean\",\n",
    "                    \"summary_bg_median\",\n",
    "                    \"summary_bg_n\",\n",
    "                    \"summary_bg_p05\",\n",
    "                    \"summary_bg_p95\",\n",
    "                    \"summary_bg_stdv\",\n",
    "                    \"summary_csf_k\",\n",
    "                    \"summary_csf_mad\",\n",
    "                    \"summary_csf_mean\",\n",
    "                    \"summary_csf_median\",\n",
    "                    \"summary_csf_n\",\n",
    "                    \"summary_csf_p05\",\n",
    "                    \"summary_csf_p95\",\n",
    "                    \"summary_csf_stdv\",\n",
    "                    \"summary_gm_k\",\n",
    "                    \"summary_gm_mad\",\n",
    "                    \"summary_gm_mean\",\n",
    "                    \"summary_gm_median\",\n",
    "                    \"summary_gm_n\",\n",
    "                    \"summary_gm_p05\",\n",
    "                    \"summary_gm_p95\",\n",
    "                    \"summary_gm_stdv\",\n",
    "                    \"summary_wm_k\",\n",
    "                    \"summary_wm_mad\",\n",
    "                    \"summary_wm_mean\",\n",
    "                    \"summary_wm_median\",\n",
    "                    \"summary_wm_n\",\n",
    "                    \"summary_wm_p05\",\n",
    "                    \"summary_wm_p95\",\n",
    "                    \"summary_wm_stdv\",\n",
    "                    \"tpm_overlap_csf\",\n",
    "                    \"tpm_overlap_gm\",\n",
    "                    \"tpm_overlap_wm\",\n",
    "                    \"wm2max\"\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds_processed = preprocessor.fit_transform(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict model.fit (th=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes of the new dataset\n",
    "y_pred = model.predict(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the index of the excluded ones to a list\n",
    "excluded = []\n",
    "for i, x in enumerate(y_pred):\n",
    "    if x == 0: # 0 is excluded\n",
    "        excluded.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict mode.predict_proba (th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_scores = model.predict_proba(ds)[:, 0] # 0 for excluded according to the model training, or 1 if model trained with SHIP dataset\n",
    "print(f\"Median score: {np.median(y_scores):.3f}\")\n",
    "print(f\"P95 score: {np.percentile(y_scores, 95):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many values > threshold from y_scores\n",
    "threshold = 0.5\n",
    "count = (y_scores > threshold).sum()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of values > threshold from y_scores\n",
    "y_pred_idx = (y_scores > threshold).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the index of the excluded ones to a list\n",
    "excluded = []\n",
    "for i, x in enumerate(y_scores):\n",
    "    if x > threshold:\n",
    "        excluded.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluded subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"bids_name\" of the indeces in \"excluded\" in \"ds_aux\"\n",
    "excluded_bids = [] # bids names\n",
    "for i in excluded:\n",
    "    excluded_bids.append(ds_aux.iloc[i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eye reports names of the excluded subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_csv = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset/bids_csv.csv\")\n",
    "# reports name of the indeces in \"excluded\" in \"df_ls\"\n",
    "excluded_names = [] # reports names\n",
    "for name in excluded_bids:\n",
    "    name = name.split('-')[1].split('_')[0]\n",
    "    sub = int(name)\n",
    "    # index of bids_csv where the column 'sub' matches 'sub'\n",
    "    index = bids_csv.index[bids_csv['sub'] == sub]\n",
    "    # value of the column 'name' of a specific index\n",
    "    report = bids_csv.iloc[index]['name'].values[0]\n",
    "    excluded_names.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excluded = pd.DataFrame({'bids_name': excluded_bids, 'name': excluded_names})\n",
    "print(f\"Excluded subjects: {len(df_excluded)}/{len(y_pred)}\") # y_scores or y_pred\n",
    "# order df_excluded by 'name'\n",
    "df_excluded = df_excluded.sort_values(by=['name'])\n",
    "print(df_excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to subjective rating (Meri, Bene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print 'bids_name' of the subjects that are both in df_excluded and in excluded_dsaux\n",
    "# common_subs = []\n",
    "# for i in df_excluded['bids_name']:\n",
    "#     if i in excluded_dsaux:\n",
    "#         common_subs.append(i)\n",
    "# print(f\"Common subjects: {len(common_subs)}/{len(excluded_dsaux)}\")\n",
    "# print(common_subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluded subjects to an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_excluded to an excel file\n",
    "df_excluded.to_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy subjects' reports to a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "reports_folder = '/home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset'\n",
    "output_folder = '/home/jaimebarranco/Downloads/excluded_mriqclearn_N183_NoBrainIQMs_th0389'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# copy html reports from reports_folder that match the subjects in excluded dataframe to output_folder\n",
    "for i in range(len(excluded)):\n",
    "    subject = df_excluded['name'].values[i]\n",
    "    for filename in os.listdir(reports_folder):\n",
    "        if filename.startswith(f'{subject}_report'):\n",
    "            shutil.copy(f'{reports_folder}/{filename}', f'{output_folder}/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare excluded subjects by folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder1 = '/home/jaimebarranco/Downloads/excluded_N183_NoBrainIQMs_th043'\n",
    "folder2 = '/home/jaimebarranco/Downloads/excluded_mriqclearn_N183_NoBrainIQMs_th0389'\n",
    "\n",
    "# number of files in folders\n",
    "num_files_folder1 = len(os.listdir(folder1))\n",
    "num_files_folder2 = len(os.listdir(folder2))\n",
    "\n",
    "# compare the html reports in folder1 and folder2\n",
    "count = 0\n",
    "if num_files_folder1 <= num_files_folder2: # folder with less files to do the loop with\n",
    "    for filename in os.listdir(folder1):\n",
    "        if filename in os.listdir(folder2):\n",
    "            print(f'{filename} is in both folders')\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f'{filename} is only in folder1')\n",
    "    print(f'\\n{count}/{len(os.listdir(folder1))} html reports are in both folders')\n",
    "else:\n",
    "    for filename in os.listdir(folder2):\n",
    "        if filename in os.listdir(folder1):\n",
    "            print(f'{filename} is in both folders')\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f'{filename} is only in folder2')\n",
    "    print(f'\\n{count}/{len(os.listdir(folder2))} html reports are in both folders')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare excluded subjects by threshold\n",
    "\n",
    "If we increase the threshold, we would have less excluded subjects. But were those subjects excluded by me as well? Let's see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel1 = pd.read_excel('/home/jaimebarranco/Downloads/excluded_mriqclearn_N183_NoBrainIQMs_th0389.xlsx')\n",
    "excel2 = pd.read_excel('/home/jaimebarranco/Downloads/excluded_mriqclearn_N183_NoBrainIQMs_th043.xlsx')\n",
    "# excel2 = df_excluded\n",
    "\n",
    "print(f'{len(excel1)} subjects in excel1')\n",
    "print(f'{len(excel2)} subjects in excel2')\n",
    "\n",
    "# subdataframe of those subjects with equal 'bids_name' in both dataframes\n",
    "common_subs1 = excel1[excel1['bids_name'].isin(excel2['bids_name'])]\n",
    "common_subs2 = excel2[excel2['bids_name'].isin(excel1['bids_name'])] # to check intra-rater reliability\n",
    "\n",
    "# percentage of excluded subjects in 'common_subs2'\n",
    "print(f\"Number of excluded subjects: {common_subs2['my_rate'].value_counts()[0]}/{len(common_subs2)} ==> {common_subs2['my_rate'].value_counts()[0]/len(common_subs2)*100:2f}%\")\n",
    "\n",
    "# how many of those subjects had the same 'my_rate' in both dataframes\n",
    "count = 0\n",
    "for i in range(len(common_subs1)):\n",
    "    if common_subs1['my_rate'].values[i] == common_subs2['my_rate'].values[i]:\n",
    "        count += 1\n",
    "print(f'\\n{count}/{len(common_subs1)} out of {len(excel2)} subjects have the same my_rate in both dataframes \\n{len(common_subs1)-count} subjects have different my_rate \\n')\n",
    "\n",
    "# which of them don't have the same 'my_rate' in both dataframes\n",
    "for i in range(len(common_subs1)):\n",
    "    if common_subs1['my_rate'].values[i] != common_subs2['my_rate'].values[i]:\n",
    "        print(f'{common_subs1[\"name\"].values[i]} has {common_subs1[\"my_rate\"].values[i]} in excel1 and {common_subs2[\"my_rate\"].values[i]} in excel2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of '0' in \"my_rate\" column\n",
    "common_subs = common_subs1\n",
    "zeros = common_subs['my_rate'].value_counts()[0]\n",
    "print(f'Excluded: {zeros}/{len(common_subs)} subjects. {zeros/len(common_subs)*100:.2f}%')\n",
    "print(common_subs)\n",
    "\n",
    "# list and percentage of the subjects with equal rating in both dataframes\n",
    "common_excluded = common_subs[common_subs['my_rate'] == 0]\n",
    "print(f'Excluded: {len(common_excluded)}/{len(common_subs)} subjects. {len(common_excluded)/len(common_subs)*100:.2f}%')\n",
    "print(common_excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are they really excluded? - My rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = \"/home/jaimebarranco/Desktop/MRI-QC/output_classifiers/excluded_mriqclearn.xlsx\"\n",
    "my_rate_df = pd.read_excel(excel_file, sheet_name=\"05\")\n",
    "\n",
    "# count the number of '0' in \"my_rate\" column\n",
    "zeros = my_rate_df['my_rate'].value_counts()[0]\n",
    "print(f'Excluded: {zeros}/{len(my_rate_df)} subjects ==> {zeros/len(my_rate_df)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe where 'my_rate' is 0\n",
    "really_excluded = my_rate_df[my_rate_df['my_rate'] == 0]\n",
    "\n",
    "# Order the dataframe by 'bids_name'\n",
    "really_excluded = really_excluded.sort_values('bids_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subject, bids, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_aux = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/df_aux.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'really_excluded' and 'df_aux' on 'name' and 'report' columns\n",
    "merged_df = really_excluded.merge(df_aux, left_on='name', right_on='report')\n",
    "# remove report and bids columns\n",
    "merged_df = merged_df.drop(columns=['bids_name', 'name'])\n",
    "# reorder columns as: subject, bids, report, my_rate, comments\n",
    "merged_df = merged_df[['subject', 'bids', 'report', 'my_rate', 'comments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the filtered dataframe to a CSV file\n",
    "merged_df.to_csv('/home/jaimebarranco/Desktop/MRI-QC/qc1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-eye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

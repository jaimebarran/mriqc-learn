{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e28d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score as auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07f2bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn')\n",
    "from mriqc_learn.datasets import load_dataset\n",
    "from mriqc_learn.models import preprocess as pp\n",
    "from mriqc_learn.models.production import init_pipeline\n",
    "from mriqc_learn.model_selection import split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c51b72",
   "metadata": {},
   "source": [
    "## Load some data\n",
    "We first load the ABIDE dataset, one of the default datasets distributed with MRIQC-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973dc0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_x, train_y), (_, _) = load_dataset(split_strategy=\"none\")\n",
    "# train_x[\"site\"] = train_y.site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c64ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel('/home/jaimebarranco/Desktop/MRI-QC/scores.xlsx', sheet_name='brainmask_avg_data')\n",
    "# add column 'site' to df with the site name 'SHIP'\n",
    "df['site'] = 'SHIP'\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['name','sub','subject','rating','rating_text','blur','blur_text','noise','noise_text','motion','motion_text','bgair','bgair_text','exclusion'])\n",
    "# y = df['rating']\n",
    "features = X.columns.tolist()\n",
    "\n",
    "# Train/test split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# train_x = train_x.drop(columns=[\n",
    "#     \"size_x\",\n",
    "#     \"size_y\",\n",
    "#     \"size_z\",\n",
    "#     \"spacing_x\",\n",
    "#     \"spacing_y\",\n",
    "#     \"spacing_z\",\n",
    "#     \"summary_bg_p05\", # all zeros\n",
    "# ])\n",
    "\n",
    "numeric_columns = train_x.columns.tolist()\n",
    "\n",
    "ratings = np.array([\"Exclude\"] * len(train_x))\n",
    "ratings[train_y.values < 1] = \"Exclude\"\n",
    "ratings[train_y.values >= 1] = \"Accept\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f8885",
   "metadata": {},
   "source": [
    "Let's pick the ratings from \"rater_3\" and binarize the three categories into only two.\n",
    "We can also see that the dataset is unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39d4bb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclude=12.121212121212121\n",
      "Accept=87.87878787878788\n"
     ]
    }
   ],
   "source": [
    "train_y = train_y.values.squeeze().astype(int)\n",
    "print(f\"Exclude={100 * (train_y < 1).sum() / len(train_y)}\")\n",
    "print(f\"Accept={100 * (train_y >= 1).sum() / len(train_y)}\")\n",
    "train_y[train_y < 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74bde49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discard=14.168937329700272\n",
      "Doubtful=1.5440508628519527\n",
      "Accept=84.28701180744777\n"
     ]
    }
   ],
   "source": [
    "# train_y = train_y[[\"rater_3\"]].values.squeeze().astype(int)\n",
    "# print(f\"Discard={100 * (train_y == -1).sum() / len(train_y)}\")\n",
    "# print(f\"Doubtful={100 * (train_y == 0).sum() / len(train_y)}\")\n",
    "# print(f\"Accept={100 * (train_y == 1).sum() / len(train_y)}\")\n",
    "# train_y[train_y < 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4ec3e",
   "metadata": {},
   "source": [
    "Let's print out a pretty view of the data table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3618b2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cjv</th>\n",
       "      <th>cnr</th>\n",
       "      <th>efc</th>\n",
       "      <th>fber</th>\n",
       "      <th>fwhm_avg</th>\n",
       "      <th>fwhm_x</th>\n",
       "      <th>fwhm_y</th>\n",
       "      <th>fwhm_z</th>\n",
       "      <th>icvs_csf</th>\n",
       "      <th>icvs_gm</th>\n",
       "      <th>...</th>\n",
       "      <th>summary_wm_mean</th>\n",
       "      <th>summary_wm_median</th>\n",
       "      <th>summary_wm_n</th>\n",
       "      <th>summary_wm_p05</th>\n",
       "      <th>summary_wm_p95</th>\n",
       "      <th>summary_wm_stdv</th>\n",
       "      <th>tpm_overlap_csf</th>\n",
       "      <th>tpm_overlap_gm</th>\n",
       "      <th>tpm_overlap_wm</th>\n",
       "      <th>wm2max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.448414</td>\n",
       "      <td>3.114049</td>\n",
       "      <td>0.597335</td>\n",
       "      <td>37197.929282</td>\n",
       "      <td>3.604710</td>\n",
       "      <td>3.46635</td>\n",
       "      <td>3.90859</td>\n",
       "      <td>3.43919</td>\n",
       "      <td>0.169228</td>\n",
       "      <td>0.360908</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.161372</td>\n",
       "      <td>1000.083417</td>\n",
       "      <td>352123</td>\n",
       "      <td>933.288886</td>\n",
       "      <td>1083.555735</td>\n",
       "      <td>45.994151</td>\n",
       "      <td>0.169087</td>\n",
       "      <td>0.422903</td>\n",
       "      <td>0.515549</td>\n",
       "      <td>0.603553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.510556</td>\n",
       "      <td>2.655019</td>\n",
       "      <td>0.581888</td>\n",
       "      <td>18742.146867</td>\n",
       "      <td>3.547583</td>\n",
       "      <td>3.44738</td>\n",
       "      <td>3.74877</td>\n",
       "      <td>3.44660</td>\n",
       "      <td>0.218436</td>\n",
       "      <td>0.338062</td>\n",
       "      <td>...</td>\n",
       "      <td>1005.749652</td>\n",
       "      <td>1000.104941</td>\n",
       "      <td>207191</td>\n",
       "      <td>924.826720</td>\n",
       "      <td>1105.795424</td>\n",
       "      <td>56.239391</td>\n",
       "      <td>0.175538</td>\n",
       "      <td>0.409606</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.485838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.503120</td>\n",
       "      <td>2.746299</td>\n",
       "      <td>0.573094</td>\n",
       "      <td>20870.499605</td>\n",
       "      <td>3.566697</td>\n",
       "      <td>3.53848</td>\n",
       "      <td>3.75553</td>\n",
       "      <td>3.40608</td>\n",
       "      <td>0.281562</td>\n",
       "      <td>0.327149</td>\n",
       "      <td>...</td>\n",
       "      <td>1004.660501</td>\n",
       "      <td>1000.094484</td>\n",
       "      <td>177628</td>\n",
       "      <td>920.598422</td>\n",
       "      <td>1103.779523</td>\n",
       "      <td>56.302368</td>\n",
       "      <td>0.158704</td>\n",
       "      <td>0.368002</td>\n",
       "      <td>0.451359</td>\n",
       "      <td>0.512418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.406657</td>\n",
       "      <td>3.377574</td>\n",
       "      <td>0.539746</td>\n",
       "      <td>31178.174972</td>\n",
       "      <td>3.571273</td>\n",
       "      <td>3.47532</td>\n",
       "      <td>3.81148</td>\n",
       "      <td>3.42702</td>\n",
       "      <td>0.220583</td>\n",
       "      <td>0.376211</td>\n",
       "      <td>...</td>\n",
       "      <td>1002.698864</td>\n",
       "      <td>1000.083453</td>\n",
       "      <td>206828</td>\n",
       "      <td>936.484522</td>\n",
       "      <td>1077.954585</td>\n",
       "      <td>43.285126</td>\n",
       "      <td>0.169976</td>\n",
       "      <td>0.443589</td>\n",
       "      <td>0.516135</td>\n",
       "      <td>0.601794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.387697</td>\n",
       "      <td>3.587771</td>\n",
       "      <td>0.522215</td>\n",
       "      <td>26844.481837</td>\n",
       "      <td>3.546927</td>\n",
       "      <td>3.35994</td>\n",
       "      <td>3.84124</td>\n",
       "      <td>3.43960</td>\n",
       "      <td>0.191132</td>\n",
       "      <td>0.402675</td>\n",
       "      <td>...</td>\n",
       "      <td>1002.623141</td>\n",
       "      <td>1000.059080</td>\n",
       "      <td>173073</td>\n",
       "      <td>933.443594</td>\n",
       "      <td>1080.936658</td>\n",
       "      <td>45.078082</td>\n",
       "      <td>0.158113</td>\n",
       "      <td>0.448850</td>\n",
       "      <td>0.512629</td>\n",
       "      <td>0.579524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.516005</td>\n",
       "      <td>2.664041</td>\n",
       "      <td>0.598902</td>\n",
       "      <td>14380.006944</td>\n",
       "      <td>3.694067</td>\n",
       "      <td>3.52521</td>\n",
       "      <td>4.04490</td>\n",
       "      <td>3.51209</td>\n",
       "      <td>0.295019</td>\n",
       "      <td>0.314556</td>\n",
       "      <td>...</td>\n",
       "      <td>1005.308022</td>\n",
       "      <td>1000.111644</td>\n",
       "      <td>161754</td>\n",
       "      <td>913.470519</td>\n",
       "      <td>1114.541916</td>\n",
       "      <td>61.525191</td>\n",
       "      <td>0.135471</td>\n",
       "      <td>0.333124</td>\n",
       "      <td>0.398176</td>\n",
       "      <td>0.471318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.448091</td>\n",
       "      <td>3.094118</td>\n",
       "      <td>0.543796</td>\n",
       "      <td>28555.917519</td>\n",
       "      <td>3.500230</td>\n",
       "      <td>3.33013</td>\n",
       "      <td>3.76717</td>\n",
       "      <td>3.40339</td>\n",
       "      <td>0.215502</td>\n",
       "      <td>0.381438</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.556587</td>\n",
       "      <td>1000.062877</td>\n",
       "      <td>175130</td>\n",
       "      <td>930.591960</td>\n",
       "      <td>1088.987413</td>\n",
       "      <td>48.578024</td>\n",
       "      <td>0.170574</td>\n",
       "      <td>0.444431</td>\n",
       "      <td>0.521019</td>\n",
       "      <td>0.533905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.445249</td>\n",
       "      <td>3.163178</td>\n",
       "      <td>0.580320</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.503080</td>\n",
       "      <td>3.34008</td>\n",
       "      <td>3.73391</td>\n",
       "      <td>3.43525</td>\n",
       "      <td>0.205994</td>\n",
       "      <td>0.381840</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.561835</td>\n",
       "      <td>1000.086505</td>\n",
       "      <td>228421</td>\n",
       "      <td>929.916123</td>\n",
       "      <td>1089.111214</td>\n",
       "      <td>48.832193</td>\n",
       "      <td>0.187022</td>\n",
       "      <td>0.451585</td>\n",
       "      <td>0.519289</td>\n",
       "      <td>0.575023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.445324</td>\n",
       "      <td>3.058757</td>\n",
       "      <td>0.554685</td>\n",
       "      <td>30115.786983</td>\n",
       "      <td>3.620553</td>\n",
       "      <td>3.49549</td>\n",
       "      <td>3.85356</td>\n",
       "      <td>3.51261</td>\n",
       "      <td>0.221696</td>\n",
       "      <td>0.372123</td>\n",
       "      <td>...</td>\n",
       "      <td>1004.453785</td>\n",
       "      <td>1000.055751</td>\n",
       "      <td>230176</td>\n",
       "      <td>936.090105</td>\n",
       "      <td>1088.865944</td>\n",
       "      <td>46.824035</td>\n",
       "      <td>0.172665</td>\n",
       "      <td>0.427342</td>\n",
       "      <td>0.510288</td>\n",
       "      <td>0.613959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.458780</td>\n",
       "      <td>3.026696</td>\n",
       "      <td>0.530533</td>\n",
       "      <td>31479.275776</td>\n",
       "      <td>3.534280</td>\n",
       "      <td>3.36246</td>\n",
       "      <td>3.81101</td>\n",
       "      <td>3.42937</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>...</td>\n",
       "      <td>1004.958362</td>\n",
       "      <td>1000.102938</td>\n",
       "      <td>193978</td>\n",
       "      <td>927.668848</td>\n",
       "      <td>1098.723008</td>\n",
       "      <td>52.734446</td>\n",
       "      <td>0.154101</td>\n",
       "      <td>0.433499</td>\n",
       "      <td>0.495507</td>\n",
       "      <td>0.503351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cjv       cnr       efc          fber  fwhm_avg   fwhm_x   fwhm_y  \\\n",
       "57  0.448414  3.114049  0.597335  37197.929282  3.604710  3.46635  3.90859   \n",
       "80  0.510556  2.655019  0.581888  18742.146867  3.547583  3.44738  3.74877   \n",
       "73  0.503120  2.746299  0.573094  20870.499605  3.566697  3.53848  3.75553   \n",
       "43  0.406657  3.377574  0.539746  31178.174972  3.571273  3.47532  3.81148   \n",
       "60  0.387697  3.587771  0.522215  26844.481837  3.546927  3.35994  3.84124   \n",
       "..       ...       ...       ...           ...       ...      ...      ...   \n",
       "79  0.516005  2.664041  0.598902  14380.006944  3.694067  3.52521  4.04490   \n",
       "67  0.448091  3.094118  0.543796  28555.917519  3.500230  3.33013  3.76717   \n",
       "64  0.445249  3.163178  0.580320     -1.000000  3.503080  3.34008  3.73391   \n",
       "47  0.445324  3.058757  0.554685  30115.786983  3.620553  3.49549  3.85356   \n",
       "44  0.458780  3.026696  0.530533  31479.275776  3.534280  3.36246  3.81101   \n",
       "\n",
       "     fwhm_z  icvs_csf   icvs_gm  ...  summary_wm_mean  summary_wm_median  \\\n",
       "57  3.43919  0.169228  0.360908  ...      1003.161372        1000.083417   \n",
       "80  3.44660  0.218436  0.338062  ...      1005.749652        1000.104941   \n",
       "73  3.40608  0.281562  0.327149  ...      1004.660501        1000.094484   \n",
       "43  3.42702  0.220583  0.376211  ...      1002.698864        1000.083453   \n",
       "60  3.43960  0.191132  0.402675  ...      1002.623141        1000.059080   \n",
       "..      ...       ...       ...  ...              ...                ...   \n",
       "79  3.51209  0.295019  0.314556  ...      1005.308022        1000.111644   \n",
       "67  3.40339  0.215502  0.381438  ...      1003.556587        1000.062877   \n",
       "64  3.43525  0.205994  0.381840  ...      1003.561835        1000.086505   \n",
       "47  3.51261  0.221696  0.372123  ...      1004.453785        1000.055751   \n",
       "44  3.42937  0.196113  0.367899  ...      1004.958362        1000.102938   \n",
       "\n",
       "    summary_wm_n  summary_wm_p05  summary_wm_p95  summary_wm_stdv  \\\n",
       "57        352123      933.288886     1083.555735        45.994151   \n",
       "80        207191      924.826720     1105.795424        56.239391   \n",
       "73        177628      920.598422     1103.779523        56.302368   \n",
       "43        206828      936.484522     1077.954585        43.285126   \n",
       "60        173073      933.443594     1080.936658        45.078082   \n",
       "..           ...             ...             ...              ...   \n",
       "79        161754      913.470519     1114.541916        61.525191   \n",
       "67        175130      930.591960     1088.987413        48.578024   \n",
       "64        228421      929.916123     1089.111214        48.832193   \n",
       "47        230176      936.090105     1088.865944        46.824035   \n",
       "44        193978      927.668848     1098.723008        52.734446   \n",
       "\n",
       "    tpm_overlap_csf  tpm_overlap_gm  tpm_overlap_wm    wm2max  \n",
       "57         0.169087        0.422903        0.515549  0.603553  \n",
       "80         0.175538        0.409606        0.501502  0.485838  \n",
       "73         0.158704        0.368002        0.451359  0.512418  \n",
       "43         0.169976        0.443589        0.516135  0.601794  \n",
       "60         0.158113        0.448850        0.512629  0.579524  \n",
       "..              ...             ...             ...       ...  \n",
       "79         0.135471        0.333124        0.398176  0.471318  \n",
       "67         0.170574        0.444431        0.521019  0.533905  \n",
       "64         0.187022        0.451585        0.519289  0.575023  \n",
       "47         0.172665        0.427342        0.510288  0.613959  \n",
       "44         0.154101        0.433499        0.495507  0.503351  \n",
       "\n",
       "[66 rows x 68 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c76905",
   "metadata": {},
   "source": [
    "## Cross-validation of the default classifier\n",
    "Let's cross-validate the performance of our classifier using a Leave-one-site-out strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0143cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a splitting strategy\n",
    "outer_cv = split.LeavePSitesOut(1, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992f5cc",
   "metadata": {},
   "source": [
    "We can now feed the model into the cross-validation loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd4b3803",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot extract 1 if the total number of groups is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/a-eye/lib/python3.8/site-packages/joblib/parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[1;32m    864\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[1;32m    865\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/a-eye/lib/python3.8/queue.py:167\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 167\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    168\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/docs/notebooks/Tutorial.ipynb Cell 14\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://tunnel%2Blinux-pep3/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/docs/notebooks/Tutorial.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m cv_score \u001b[39m=\u001b[39m cross_val_score(\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Blinux-pep3/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/docs/notebooks/Tutorial.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     init_pipeline(),\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Blinux-pep3/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/docs/notebooks/Tutorial.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_x,\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Blinux-pep3/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/docs/notebooks/Tutorial.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     y\u001b[39m=\u001b[39;49mtrain_y,\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Blinux-pep3/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/docs/notebooks/Tutorial.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     cv\u001b[39m=\u001b[39;49mouter_cv,\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Blinux-pep3/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/docs/notebooks/Tutorial.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     scoring\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Blinux-pep3/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/docs/notebooks/Tutorial.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Blinux-pep3/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/docs/notebooks/Tutorial.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/a-eye/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/a-eye/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/a-eye/lib/python3.8/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/miniconda3/envs/a-eye/lib/python3.8/site-packages/joblib/parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    870\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[1;32m    871\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[0;32m--> 873\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[1;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/a-eye/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/mriqc_learn/model_selection/split.py:102\u001b[0m, in \u001b[0;36mLeavePSitesOut.split\u001b[0;34m(self, X, y, groups, return_key)\u001b[0m\n\u001b[1;32m    100\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    101\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m--> 102\u001b[0m \u001b[39mfor\u001b[39;00m labels, test_index \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_test_masks(X, y, groups, return_key\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    103\u001b[0m     train_index \u001b[39m=\u001b[39m indices[np\u001b[39m.\u001b[39mlogical_not(test_index)]\n\u001b[1;32m    104\u001b[0m     test_index \u001b[39m=\u001b[39m indices[test_index]\n",
      "File \u001b[0;32m/mnt/sda1/Repos/mriqc/mriqc-learn/mriqc-learn/mriqc_learn/model_selection/split.py:55\u001b[0m, in \u001b[0;36mLeavePSitesOut._iter_test_masks\u001b[0;34m(self, X, y, groups, return_key)\u001b[0m\n\u001b[1;32m     52\u001b[0m _groups \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(groups)\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_groups) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_groups:\n\u001b[0;32m---> 55\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot extract \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_groups\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mif the total number of groups is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(_groups)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     61\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mvalues\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot extract 1 if the total number of groups is 1"
     ]
    }
   ],
   "source": [
    "cv_score = cross_val_score(\n",
    "    init_pipeline(),\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    "    cv=outer_cv,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc225b6",
   "metadata": {},
   "source": [
    "After one or two minutes, the scores have been caculated for each of the 14 folds our splitter created.\n",
    "The average performance is AUC=0.885."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_score)\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cv_score = {}\n",
    "for train_index, (site, test_index) in outer_cv.split(train_x, y=train_y, return_key=True):\n",
    "    # Validate on test fold\n",
    "    print(f\"Validating on left-out site ({site})...\")\n",
    "    model_split = init_pipeline()\n",
    "    model_split = model_split.fit(train_x.iloc[train_index], train_y[train_index])\n",
    "    custom_cv_score[site] = auc(train_y[test_index], model_split.predict(train_x.iloc[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_cv_score)\n",
    "np.mean(list(custom_cv_score.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622dc24",
   "metadata": {},
   "source": [
    "We now train the model on all available training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_pipeline().fit(\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ac340",
   "metadata": {},
   "source": [
    "We can easily see the effects of overfitting by evaluating the classifier on the same folds we used for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_cv_score = {}\n",
    "for train_index, (site, test_index) in outer_cv.split(train_x, y=train_y, return_key=True):\n",
    "    print(f\"Validating on left-out site ({site})...\")\n",
    "    overfit_cv_score[site] = auc(train_y[test_index], model.predict(train_x.iloc[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([overfit_cv_score[s] - custom_cv_score[s] for s in overfit_cv_score.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(train_y, model.predict(train_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4292f",
   "metadata": {},
   "source": [
    "## Evaluating on held-out dataset\n",
    "We first load the held-out dataset in, and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_x, test_y), (_, _) = load_dataset(\"ds030\", split_strategy=\"none\")\n",
    "test_x[\"site\"] = test_y.site\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_ghost = test_y.has_ghost.values.astype(bool)\n",
    "test_y = test_y[[\"rater_1\"]].values.squeeze().astype(int)\n",
    "print(f\"Discard={100 * (test_y == -1).sum() / len(test_y)}\")\n",
    "print(f\"Doubtful={100 * (test_y == 0).sum() / len(test_y)}\")\n",
    "print(f\"Accept={100 * (test_y == 1).sum() / len(test_y)}\")\n",
    "test_y[test_y < 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(test_y, model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33792116",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(test_y[~has_ghost], model.predict(test_x[~has_ghost]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, model.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y[~has_ghost], model.predict(test_x[~has_ghost])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cded3e3",
   "metadata": {},
   "source": [
    "## Nested cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e57e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = [{\n",
    "    \"scale__unit_variance\": [True, False],\n",
    "    \"scale__with_centering\": [True, False],\n",
    "    \"site_pred__disable\": [False, True],\n",
    "    \"winnow__disable\": [False, True],\n",
    "    \"svc__kernel\": [\"rbf\"],\n",
    "    \"svc__C\": [10],\n",
    "    \"svc__gamma\": [0.1],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV with parameter optimization\n",
    "inner_cv = split.LeavePSitesOut(1, robust=True)\n",
    "inner_cv.get_n_splits(X=train_x, y=train_y)\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=p_grid,\n",
    "    cv=inner_cv,\n",
    "    n_jobs=30,\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "# clf.fit(train_x, y=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d007f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_score = cross_val_score(\n",
    "    clf,\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    "    cv=outer_cv,\n",
    "    scoring=\"roc_auc\",\n",
    "    verbose=10,\n",
    "    n_jobs=16,\n",
    ")\n",
    "nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd499df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
